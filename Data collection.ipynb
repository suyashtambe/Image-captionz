{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Suyash Tambe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from flask import Flask, request, jsonify\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments, GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON dataset\n",
    "with open(r'C:\\Users\\Suyash Tambe\\Desktop\\shayari generator\\quotes.json', 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Convert JSON data to a pandas DataFrame\n",
    "df_json = pd.DataFrame(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TXT dataset\n",
    "with open(r'C:\\Users\\Suyash Tambe\\Desktop\\shayari generator\\hindi_shayari.txt', 'r', encoding='utf-8') as file:\n",
    "    txt_data = file.readlines()\n",
    "\n",
    "# Convert TXT data to a pandas DataFrame\n",
    "df_txt = pd.DataFrame(txt_data, columns=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV datasets\n",
    "f\n",
    "df_csv = pd.read_csv(r'C:\\Users\\Suyash Tambe\\Desktop\\shayari generator\\quotes_filtered_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combined records: 53655\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat([df_json, df_txt, df_csv], ignore_index=True)\n",
    "# Save combined dataset\n",
    "combined_df.to_csv('combined_quotes.csv', index=False, encoding='utf-8')\n",
    "print(f'Total combined records: {len(combined_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Suyash\n",
      "[nltk_data]     Tambe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove special characters\n",
    "        text = re.sub(r'\\W', ' ', text)\n",
    "        # Remove single characters\n",
    "        text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "        # Remove multiple spaces\n",
    "        text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove stopwords\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all entries to strings and handle missing values\n",
    "combined_df['text'] = combined_df['text'].astype(str).fillna('')\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "combined_df['processed_text'] = combined_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Save the preprocessed data to a CSV file\n",
    "combined_df.to_csv('processed_shayaris_quotes.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(f'Total combined records: {len(combined_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2-medium'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Suyash Tambe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "  1%|          | 500/55809 [43:05<82:05:01,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4331, 'grad_norm': 4.322802543640137, 'learning_rate': 4.955473131573761e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 1000/55809 [1:26:27<77:27:36,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3456, 'grad_norm': 3.2921230792999268, 'learning_rate': 4.910677489293842e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 1500/55809 [2:10:01<76:52:33,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2545, 'grad_norm': 3.165480136871338, 'learning_rate': 4.8658818470139225e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–Ž         | 2000/55809 [2:53:38<79:38:44,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2445, 'grad_norm': 2.986248254776001, 'learning_rate': 4.821086204734004e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 2500/55809 [3:36:45<79:29:56,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2377, 'grad_norm': 2.7617545127868652, 'learning_rate': 4.776290562454085e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 3000/55809 [4:19:59<74:21:23,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1937, 'grad_norm': 3.256549596786499, 'learning_rate': 4.731494920174166e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 3500/55809 [5:03:11<76:18:58,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1968, 'grad_norm': 2.987262010574341, 'learning_rate': 4.6866992778942464e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 4000/55809 [5:46:27<75:01:56,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1958, 'grad_norm': 2.9487757682800293, 'learning_rate': 4.641903635614327e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 4500/55809 [6:29:28<70:22:08,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1746, 'grad_norm': 2.8795626163482666, 'learning_rate': 4.5971975846189687e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 5000/55809 [7:12:39<74:46:40,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1539, 'grad_norm': 2.5967495441436768, 'learning_rate': 4.5524019423390495e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 5500/55809 [7:55:46<71:03:18,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1347, 'grad_norm': 3.0910046100616455, 'learning_rate': 4.507606300059131e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 6000/55809 [8:38:49<68:58:06,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1543, 'grad_norm': 3.1369102001190186, 'learning_rate': 4.462810657779212e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 6500/55809 [9:21:33<72:18:05,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1068, 'grad_norm': 2.3991172313690186, 'learning_rate': 4.4181046067838525e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 7000/55809 [10:04:26<66:40:02,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1273, 'grad_norm': 2.3422632217407227, 'learning_rate': 4.373308964503933e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 7500/55809 [10:47:36<70:29:10,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1323, 'grad_norm': 2.341602325439453, 'learning_rate': 4.328513322224014e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 8000/55809 [11:30:18<69:42:57,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1261, 'grad_norm': 2.4263062477111816, 'learning_rate': 4.2837176799440956e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 8500/55809 [12:13:29<67:10:18,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1062, 'grad_norm': 2.165980339050293, 'learning_rate': 4.2389220376641764e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 9000/55809 [12:56:33<66:14:43,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.117, 'grad_norm': 2.2414004802703857, 'learning_rate': 4.194215986668817e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 9500/55809 [13:39:09<65:38:31,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0763, 'grad_norm': 2.3656859397888184, 'learning_rate': 4.149420344388898e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 10000/55809 [14:22:03<64:31:16,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0688, 'grad_norm': 2.053394079208374, 'learning_rate': 4.104624702108979e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 10500/55809 [15:05:06<66:31:10,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1071, 'grad_norm': 2.15468692779541, 'learning_rate': 4.05982905982906e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–‰        | 11000/55809 [15:48:11<64:14:35,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0833, 'grad_norm': 2.0185866355895996, 'learning_rate': 4.015033417549141e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 11500/55809 [16:30:57<64:10:26,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0926, 'grad_norm': 2.2321746349334717, 'learning_rate': 3.970237775269222e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 12000/55809 [17:14:12<62:53:54,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0861, 'grad_norm': 2.1073265075683594, 'learning_rate': 3.925442132989303e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 12500/55809 [17:57:13<60:12:23,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0701, 'grad_norm': 2.239762783050537, 'learning_rate': 3.880646490709384e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 13000/55809 [19:25:36<58:16:21,  4.90s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0744, 'grad_norm': 1.9367420673370361, 'learning_rate': 3.835850848429465e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 13500/55809 [20:07:23<59:15:21,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0553, 'grad_norm': 2.1576125621795654, 'learning_rate': 3.791144797434106e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 14000/55809 [20:50:15<55:08:37,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0405, 'grad_norm': 2.0548648834228516, 'learning_rate': 3.746349155154187e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–Œ       | 14500/55809 [21:33:44<58:34:49,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0446, 'grad_norm': 2.014920949935913, 'learning_rate': 3.701553512874268e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 15000/55809 [22:15:25<56:16:40,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0517, 'grad_norm': 1.9528290033340454, 'learning_rate': 3.656757870594349e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 15500/55809 [22:57:22<56:57:51,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0303, 'grad_norm': 2.187955379486084, 'learning_rate': 3.6120518195989895e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–Š       | 16000/55809 [23:39:26<55:05:24,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0323, 'grad_norm': 1.9500113725662231, 'learning_rate': 3.56725617731907e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–‰       | 16500/55809 [24:22:40<55:30:42,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0374, 'grad_norm': 1.93002450466156, 'learning_rate': 3.522460535039152e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 17000/55809 [25:04:05<46:07:40,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0232, 'grad_norm': 1.8924616575241089, 'learning_rate': 3.4776648927592326e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆâ–      | 17500/55809 [25:44:51<45:08:36,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0048, 'grad_norm': 1.9501159191131592, 'learning_rate': 3.4329588417638734e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 18000/55809 [26:20:11<44:31:58,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0171, 'grad_norm': 2.033876657485962, 'learning_rate': 3.388163199483954e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18500/55809 [26:55:31<43:56:49,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9911, 'grad_norm': 2.187822103500366, 'learning_rate': 3.343367557204035e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 19000/55809 [27:30:52<43:21:05,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0268, 'grad_norm': 1.9580587148666382, 'learning_rate': 3.2985719149241165e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 19500/55809 [28:06:00<42:29:17,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0074, 'grad_norm': 1.8056719303131104, 'learning_rate': 3.253776272644197e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 20000/55809 [28:41:05<41:53:28,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0289, 'grad_norm': 2.0633480548858643, 'learning_rate': 3.209070221648838e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20500/55809 [29:16:11<41:18:33,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0074, 'grad_norm': 1.8750252723693848, 'learning_rate': 3.1642745793689195e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 21000/55809 [29:51:40<41:43:10,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.011, 'grad_norm': 1.9522212743759155, 'learning_rate': 3.119478937089e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–Š      | 21500/55809 [30:32:09<47:18:59,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0023, 'grad_norm': 1.8744316101074219, 'learning_rate': 3.074683294809081e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 22000/55809 [31:17:51<50:45:45,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0168, 'grad_norm': 2.00217342376709, 'learning_rate': 3.029887652529162e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22500/55809 [32:03:23<56:42:23,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0057, 'grad_norm': 1.9757813215255737, 'learning_rate': 2.985092010249243e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 23000/55809 [32:47:35<48:39:35,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9659, 'grad_norm': 2.021411418914795, 'learning_rate': 2.9402963679693242e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23500/55809 [33:31:44<46:08:27,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0142, 'grad_norm': 2.031052350997925, 'learning_rate': 2.895590316973965e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 24000/55809 [34:15:46<47:17:04,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9934, 'grad_norm': 2.0038669109344482, 'learning_rate': 2.850794674694046e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24500/55809 [34:59:30<46:00:57,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9766, 'grad_norm': 2.003955125808716, 'learning_rate': 2.8059990324141266e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 25000/55809 [35:43:08<45:59:33,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9879, 'grad_norm': 2.1188926696777344, 'learning_rate': 2.7612033901342077e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 25500/55809 [36:27:04<45:07:24,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9952, 'grad_norm': 1.9964752197265625, 'learning_rate': 2.716407747854289e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26000/55809 [37:10:43<43:55:52,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9982, 'grad_norm': 2.3614349365234375, 'learning_rate': 2.67170169685893e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 26500/55809 [37:54:38<43:15:19,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9753, 'grad_norm': 1.735323429107666, 'learning_rate': 2.6269060545790107e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 27000/55809 [38:38:40<41:37:17,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9854, 'grad_norm': 2.21685791015625, 'learning_rate': 2.582110412299092e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 27500/55809 [39:22:34<41:44:16,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.981, 'grad_norm': 1.9705712795257568, 'learning_rate': 2.5373147700191723e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28000/55809 [40:06:17<40:18:11,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9729, 'grad_norm': 2.0474400520324707, 'learning_rate': 2.4925191277392538e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 28500/55809 [40:49:57<39:00:51,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9576, 'grad_norm': 2.0017971992492676, 'learning_rate': 2.4478130767438946e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29000/55809 [41:34:01<39:26:46,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9749, 'grad_norm': 2.1469178199768066, 'learning_rate': 2.4030174344639754e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 29500/55809 [42:17:47<38:46:05,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9531, 'grad_norm': 1.9425671100616455, 'learning_rate': 2.3582217921840562e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30000/55809 [43:01:29<38:26:26,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9808, 'grad_norm': 2.052035093307495, 'learning_rate': 2.3134261499041373e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 30500/55809 [43:45:32<35:52:32,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9828, 'grad_norm': 2.0447463989257812, 'learning_rate': 2.2686305076242185e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 31000/55809 [44:31:08<40:35:29,  5.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9786, 'grad_norm': 1.9033349752426147, 'learning_rate': 2.2239244566288592e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31500/55809 [45:12:06<34:39:54,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9589, 'grad_norm': 2.13098406791687, 'learning_rate': 2.1791288143489404e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 32000/55809 [45:51:17<29:51:11,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9565, 'grad_norm': 2.080479383468628, 'learning_rate': 2.1343331720690212e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 32500/55809 [46:33:57<28:22:06,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.97, 'grad_norm': 1.9660067558288574, 'learning_rate': 2.0895375297891023e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 33000/55809 [47:11:12<27:45:46,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9389, 'grad_norm': 1.774996280670166, 'learning_rate': 2.044831478793743e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33500/55809 [47:51:52<32:37:04,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9818, 'grad_norm': 1.9949225187301636, 'learning_rate': 2.0000358365138242e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 34000/55809 [48:35:57<30:57:27,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9751, 'grad_norm': 1.9087843894958496, 'learning_rate': 1.955240194233905e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34500/55809 [49:19:59<31:03:26,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9349, 'grad_norm': 1.98844575881958, 'learning_rate': 1.9104445519539858e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 35000/55809 [50:03:55<31:00:43,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.952, 'grad_norm': 2.2988436222076416, 'learning_rate': 1.865648909674067e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 35500/55809 [50:48:06<29:59:17,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9471, 'grad_norm': 1.9761903285980225, 'learning_rate': 1.820853267394148e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 36000/55809 [51:31:52<27:39:56,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9556, 'grad_norm': 1.9420907497406006, 'learning_rate': 1.776057625114229e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 36500/55809 [52:15:41<28:30:15,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9585, 'grad_norm': 1.9109948873519897, 'learning_rate': 1.73135157411887e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 37000/55809 [52:59:35<27:05:32,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9582, 'grad_norm': 1.8010175228118896, 'learning_rate': 1.6865559318389508e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 37500/55809 [53:43:31<27:01:13,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9405, 'grad_norm': 1.8463995456695557, 'learning_rate': 1.6417602895590316e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 38000/55809 [54:27:33<26:01:35,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9479, 'grad_norm': 1.79286527633667, 'learning_rate': 1.5969646472791127e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 38500/55809 [55:11:34<25:28:32,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9438, 'grad_norm': 1.8970857858657837, 'learning_rate': 1.5522585962837535e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 39000/55809 [55:55:41<24:40:00,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9095, 'grad_norm': 2.0091891288757324, 'learning_rate': 1.5074629540038347e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 39500/55809 [56:34:07<20:13:01,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9285, 'grad_norm': 1.9848663806915283, 'learning_rate': 1.4626673117239156e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40000/55809 [57:11:18<19:35:43,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9488, 'grad_norm': 1.9208528995513916, 'learning_rate': 1.4178716694439968e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 40500/55809 [57:48:39<22:35:36,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9209, 'grad_norm': 1.887749195098877, 'learning_rate': 1.3731656184486375e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 41000/55809 [58:27:12<18:52:24,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9375, 'grad_norm': 1.994701623916626, 'learning_rate': 1.3283699761687185e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 41500/55809 [59:05:25<18:14:04,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9228, 'grad_norm': 1.7683558464050293, 'learning_rate': 1.2835743338887993e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 42000/55809 [59:43:27<17:27:04,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9389, 'grad_norm': 2.2723100185394287, 'learning_rate': 1.2387786916088803e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 42500/55809 [60:21:29<16:49:23,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9397, 'grad_norm': 1.8151968717575073, 'learning_rate': 1.1939830493289614e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 43000/55809 [60:59:25<16:31:45,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9233, 'grad_norm': 1.9797844886779785, 'learning_rate': 1.1492769983336022e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 43500/55809 [61:37:20<15:33:28,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9264, 'grad_norm': 1.9418294429779053, 'learning_rate': 1.1044813560536831e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 44000/55809 [62:15:16<14:55:36,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9079, 'grad_norm': 1.8915907144546509, 'learning_rate': 1.0596857137737641e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 44500/55809 [62:53:12<14:17:39,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9271, 'grad_norm': 1.9580734968185425, 'learning_rate': 1.0148900714938451e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 45000/55809 [63:31:07<13:39:45,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.916, 'grad_norm': 1.9950745105743408, 'learning_rate': 9.70094429213926e-06, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45500/55809 [64:08:52<12:48:36,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8969, 'grad_norm': 1.9170658588409424, 'learning_rate': 9.25388378218567e-06, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 46000/55809 [64:46:09<12:11:27,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9122, 'grad_norm': 2.0754857063293457, 'learning_rate': 8.80592735938648e-06, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 46500/55809 [65:23:26<11:34:38,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9039, 'grad_norm': 1.8872544765472412, 'learning_rate': 8.35797093658729e-06, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 47000/55809 [66:00:41<10:56:32,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9039, 'grad_norm': 1.6525840759277344, 'learning_rate': 7.910910426633697e-06, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 47500/55809 [66:37:58<10:20:04,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9282, 'grad_norm': 2.1660056114196777, 'learning_rate': 7.4629540038345075e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 48000/55809 [67:15:15<9:42:08,  4.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9229, 'grad_norm': 2.152390718460083, 'learning_rate': 7.014997581035316e-06, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 48500/55809 [67:52:31<9:05:10,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9086, 'grad_norm': 2.1439690589904785, 'learning_rate': 6.567041158236127e-06, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 49000/55809 [68:29:48<8:27:31,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8962, 'grad_norm': 1.9721548557281494, 'learning_rate': 6.119084735436937e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 49500/55809 [69:07:28<7:56:02,  4.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9119, 'grad_norm': 2.110058307647705, 'learning_rate': 5.671128312637747e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 50000/55809 [69:45:10<7:18:26,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9136, 'grad_norm': 2.068565607070923, 'learning_rate': 5.223171889838557e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 50500/55809 [70:22:53<6:40:30,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8846, 'grad_norm': 1.934319257736206, 'learning_rate': 4.775215467039367e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51000/55809 [71:00:43<6:05:13,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9284, 'grad_norm': 1.8219486474990845, 'learning_rate': 4.327259044240176e-06, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51500/55809 [71:38:40<5:27:15,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.919, 'grad_norm': 2.0901076793670654, 'learning_rate': 3.880198534286585e-06, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 52000/55809 [72:16:38<4:49:11,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9159, 'grad_norm': 2.1522765159606934, 'learning_rate': 3.4322421114873945e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 52500/55809 [72:54:32<4:04:40,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9191, 'grad_norm': 2.164865732192993, 'learning_rate': 2.9842856886882047e-06, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 53000/55809 [73:31:31<3:27:37,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8824, 'grad_norm': 2.136652708053589, 'learning_rate': 2.5363292658890144e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 53500/55809 [74:08:29<2:50:44,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8998, 'grad_norm': 2.003671169281006, 'learning_rate': 2.088372843089824e-06, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 54000/55809 [74:45:26<2:13:48,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9117, 'grad_norm': 2.2115211486816406, 'learning_rate': 1.6413123331362326e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 54500/55809 [75:27:44<1:52:24,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8967, 'grad_norm': 2.0858142375946045, 'learning_rate': 1.1933559103370425e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 55000/55809 [76:11:45<1:09:55,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9057, 'grad_norm': 1.8896511793136597, 'learning_rate': 7.453994875378524e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 55500/55809 [76:55:44<27:26,  5.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9209, 'grad_norm': 1.9031325578689575, 'learning_rate': 2.974430647386622e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55809/55809 [77:22:49<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 278569.6543, 'train_samples_per_second': 0.801, 'train_steps_per_second': 0.2, 'train_loss': 3.0053791757762807, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./trained_model\\\\tokenizer_config.json',\n",
       " './trained_model\\\\special_tokens_map.json',\n",
       " './trained_model\\\\vocab.json',\n",
       " './trained_model\\\\merges.txt',\n",
       " './trained_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load your pretrained GPT-2 model and tokenizer\n",
    "model_name = 'gpt2-medium'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Load your combined dataset\n",
    "df = pd.read_csv(r'C:\\Users\\Suyash Tambe\\Desktop\\shayari generator\\quotes.csv')\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the splits to csv\n",
    "train_df.to_csv('train_shayaris_quotes.csv', index=False)\n",
    "test_df.to_csv('test_shayaris_quotes.csv', index=False)\n",
    "\n",
    "# Function to load dataset for language model training\n",
    "def load_dataset(file_path, tokenizer, block_size=128):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=file_path,\n",
    "        block_size=block_size,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "# Load train and test datasets\n",
    "train_dataset = load_dataset('train_shayaris_quotes.csv', tokenizer)\n",
    "test_dataset = load_dataset('test_shayaris_quotes.csv', tokenizer)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,  # Adjust batch size if necessary\n",
    "    save_steps=7000,\n",
    "    save_total_limit=2,\n",
    "    fp16=True if torch.cuda.is_available() else False,  # Enable mixed precision training if GPU is available\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained('./gpt_model')\n",
    "tokenizer.save_pretrained('./gpt_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt_model\\\\tokenizer_config.json',\n",
       " './gpt_model\\\\special_tokens_map.json',\n",
       " './gpt_model\\\\vocab.json',\n",
       " './gpt_model\\\\merges.txt',\n",
       " './gpt_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./gpt_model')\n",
    "tokenizer.save_pretrained('./gpt_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'C:\\Users\\Suyash Tambe\\Desktop\\shayari generator\\gpt_model'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Suyash Tambe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "model_name = r'C:\\Users\\Suyash Tambe\\Desktop\\shayari generator\\gpt_model'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "def generate_quote(tags, max_length=100, temperature=1.0, top_k=50, top_p=0.95):\n",
    "    # Encode the input tags\n",
    "    input_ids = tokenizer.encode(tags, return_tensors='pt').to(device)\n",
    "    \n",
    "    # Generate the quote\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        temperature=temperature,      \n",
    "        top_k=top_k,                  \n",
    "        top_p=top_p,                  \n",
    "        do_sample=True,               \n",
    "        eos_token_id=tokenizer.eos_token_id, # Ensure sentences end properly\n",
    "    )\n",
    "    \n",
    "    # Decode the output\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Split the text into sentences and take the first one\n",
    "    sentences = generated_text.split('.')\n",
    "    if len(sentences) > 1:\n",
    "        generated_text = sentences[0] + '.'\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating quotes for tags: relationship\n",
      "1. relationship, romance\"\n",
      "\"Love and kindness donâ€™t come in packages, you can have them both, but you cannot get them all the time and still leave home feeling inferior.\n",
      "2. relationship\"\n",
      "\"In a few years, the world will have enough computers to take down entire nations, and we wonâ€™t even know who is responsible for that.\n",
      "3. relationship, relationship-quotes, self-care, women-writers\"\n",
      "\"I'm interested in the way the public, especially in Washington, feels that there are no real differences between a liberal and a conservative and between the two political parties; that the country is united, not divided.\n",
      "4. relationship\n",
      "\"She had found a way to live in the past, a place in which she would never be the same; a moment in a lifetime she was gone.\n",
      "5. relationship-advice, love, relationship-quotes\"\n",
      "\"As a writer, a poet has a great deal to give.\n",
      "Generating quotes for tags: happiness, love\n",
      "6. happiness, love, pain, sorrow, suffer, suffering\"\n",
      "\"I feel like I've never been quite as happy as I was when I turned six.\n",
      "7. happiness, love-quotes, philosophy-of-life\"\n",
      "\"The first sign of good health and an active mind is a positive attitude in the morning, and a cheerful spirit in afternoon.\n",
      "8. happiness, love, philosophy, soul, spiritual-growth, wisdom\"\n",
      "You never know when something will happen that you never knew you ever were there for,Munia Khan,\"foresight, future, inspiration, inspirational, life, positive, possibilities, reality, think, tomorrow, wrong-doings, wise-words\",you-never-know-the-best-things-are-coming-soon,\"best, be-a-happy-creator, good, happiness,\n",
      "9. happiness, love-quotes, soul-mates, trust-issues\"\n",
      "\"For me, the most important thing is that I want to work at the right company, and at a place that is a really good fit, because that's my purpose in life.\n",
      "10. happiness, love\"\n",
      "The one thing I've learned to live with in all those years is that when you're fighting for something you don't want, it's easy to say it won't last long.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "tags_list = [\"relationship\", \"happiness, love\"]\n",
    "quote_counter = 1\n",
    "\n",
    "for tags in tags_list:\n",
    "    print(f\"Generating quotes for tags: {tags}\")\n",
    "    for i in range(5):  # Generate multiple quotes for each set of tags\n",
    "        quote = generate_quote(tags)\n",
    "        print(f\"{quote_counter}. {quote}\")\n",
    "        quote_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
